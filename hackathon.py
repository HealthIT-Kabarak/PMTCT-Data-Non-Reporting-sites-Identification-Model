# -*- coding: utf-8 -*-
"""hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w_R_sY9k85_VXgZkP-EmySx70nDSljCx
"""



import pandas as pd
import pandas as pd
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
import joblib
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

hts_df = pd.read_excel('hst.xlsx')
pmtct_df = pd.read_excel('pmtct.xlsx')

#merging two dataframes 

merged_df = pd.merge(hts_df, pmtct_df, on='facilityuid')

merged_df.to_csv('Combined.csv', index = False)
#cleaning
merged_df = merged_df.dropna()
merged_df.drop_duplicates(subset=['facilityuid'], inplace=True)
merged_df.drop(["ward_x","ward_y"], inplace=True, axis=1)
#merged_df

# Create target variable for classification - sites not reporting tests

merged_df['not_reporting_tests'] = 1 - merged_df['dhis2_value_x']
#merged_df['not_reporting_tests'] = merged_df['datim_value_x'] - merged_df['dhis2_value_x']
merged_df.dropna(inplace =True)

#NOT REPORTED
#print(merged_df['not_reporting_tests']) 

# Select relevant features for classification

features  = ['dhis2_value_y', 'datim_value_y','dhis2_value_x', 'datim_value_x']


# Create feature matrix and target variable
X = merged_df[features]
y = merged_df['not_reporting_tests']

# check if there are any NaN values in X or y
if X.isna().sum().sum() > 0 or y.isna().sum().sum() > 0:
    print("Rows with NaN values in X or y:")
    print(merged_df[X.isna().any(axis=1) | y.isna()])
    # drop rows with NaN values in X or y
    merged_df.dropna(inplace=True, subset=features+['not_reporting_tests'])

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)

# Create decision tree classifier
clf = DecisionTreeClassifier(random_state=42)



clf.fit(X_train, y_train)

# Export decision tree visualization to file

feature_names = [str(features[0]), str(features[1]),str(features[2]),str(features[3])]
class_names = sorted( y.unique())


class_name_str = [str(cls) for cls in class_names]

 # convert all class names to string
tree.export_graphviz(clf, out_file='pmtct-sample_data.dot', 
                     feature_names=feature_names,
                     class_names=class_name_str,
                     label='all',
                     rounded=True,
                     filled=True)


#Predict the target variable for the test set
y_pred = clf.predict(X_test)
# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)

"""# New Section"""



